The perception-monitor is a top-state structure that monitors perceptual information from
   both the input-link and svs,
It will detect discrepancies between the top-state world and perception
   and propose, investigate, and take actions to resolve those discrepancies

robot-view-filter <f>  # robot-view-filter.soar
   Reference to an svs filter that checks for intersection between the mobile robot's view volume
      and all the belief objects in the scene

top-state
   io.input-link
      self
         arm
            moving-state << moving stopped >>
   perception-monitor
   world
      robot
         arm
            moving-state << moving stopped >>
      objects
      predicates



###### robot-monitor ######
Monitors information about the robot itself

# attend-to-changed-arm-status
	self-info <self> # io.input-link.self
	change
		type changed-arm-status
		category robot

	Maintains the world.robot.arm.moving-state << moving stopped >> wme
	input-link.self.arm.moving-state << moving stopped >>
	Remove all internal-links for moved object when the arm is done moving
		And all internal-links to the moved object

# attend-to-changed-moving-state
	self-info <self> # io.input-link.self
	change
		type changed-moving-state
		category robot

	Updates world.robot.moving-state from input-link.self.moving-state

# attend-to-changed-waypoint
	new-waypoint-handle <wp-handle>
	change
		type changed-waypoint
		category robot

	Updates world.robot.current-waypoint using io.input-link.self.current-waypoint.waypoint-handle


